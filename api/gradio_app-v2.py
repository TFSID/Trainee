"""
Gradio interface for LLM Model Trainer
"""
import gradio as gr
import os
import json
import time
from datetime import datetime
from typing import Dict, List, Optional, Tuple
import pandas as pd

class ModelTrainerConfig:
    """Configuration class for model trainer"""
    def __init__(self):
        self.supported_formats = ['.json', '.jsonl', '.csv', '.txt']
        self.base_models = [
            'gpt-3.5-turbo',
            'gpt-4',
            'llama-2-7b',
            'mistral-7b',
            'bert-base'
        ]
        self.max_file_size = 100 * 1024 * 1024  # 100MB

class ModelTrainerAPI:
    """API class for model training operations"""
    
    def __init__(self, config: ModelTrainerConfig):
        self.config = config
        self.training_jobs = []
        self.trained_models = []
        
    def validate_dataset(self, file_path: str) -> Tuple[bool, str]:
        """Validate uploaded dataset"""
        if not file_path:
            return False, "No file uploaded"
        
        if not os.path.exists(file_path):
            return False, "File does not exist"
        
        file_size = os.path.getsize(file_path)
        if file_size > self.config.max_file_size:
            return False, f"File too large. Max size: {self.config.max_file_size / 1024 / 1024:.1f}MB"
        
        file_ext = os.path.splitext(file_path)[1].lower()
        if file_ext not in self.config.supported_formats:
            return False, f"Unsupported format. Supported: {', '.join(self.config.supported_formats)}"
        
        return True, "Dataset validated successfully"
    
    def start_training(self, model_name: str, base_model: str, dataset_path: str, 
                      learning_rate: float, batch_size: int, epochs: int) -> str:
        """Start model training"""
        if not model_name.strip():
            return "Error: Model name is required"
        
        is_valid, message = self.validate_dataset(dataset_path)
        if not is_valid:
            return f"Error: {message}"
        
        job_id = f"job_{len(self.training_jobs) + 1}_{int(time.time())}"
        
        training_job = {
            'id': job_id,
            'model_name': model_name,
            'base_model': base_model,
            'dataset_path': dataset_path,
            'status': 'started',
            'progress': 0,
            'learning_rate': learning_rate,
            'batch_size': batch_size,
            'epochs': epochs,
            'start_time': datetime.now().isoformat(),
            'logs': []
        }
        
        self.training_jobs.append(training_job)
        
        # Simulate training process
        self._simulate_training(job_id)
        
        return f"Training started successfully!\nJob ID: {job_id}\nModel: {model_name}\nBase Model: {base_model}"
    
    def _simulate_training(self, job_id: str):
        """Simulate training progress"""
        # In real implementation, this would be async
        job = next((j for j in self.training_jobs if j['id'] == job_id), None)
        if job:
            job['status'] = 'training'
            job['logs'].append(f"Training started at {datetime.now().strftime('%H:%M:%S')}")
    
    def get_training_status(self) -> str:
        """Get status of all training jobs"""
        if not self.training_jobs:
            return "No training jobs found"
        
        status_text = "**Training Jobs Status:**\n\n"
        
        for job in self.training_jobs:
            status_text += f"**{job['model_name']}** (ID: {job['id']})\n"
            status_text += f"- Status: {job['status'].title()}\n"
            status_text += f"- Base Model: {job['base_model']}\n"
            status_text += f"- Progress: {job['progress']}%\n"
            status_text += f"- Started: {job['start_time'][:19]}\n"
            
            if job['logs']:
                status_text += f"- Latest Log: {job['logs'][-1]}\n"
            
            status_text += "\n"
        
        return status_text
    
    def get_trained_models(self) -> str:
        """Get list of trained models"""
        completed_jobs = [job for job in self.training_jobs if job['status'] == 'completed']
        
        if not completed_jobs:
            return "No trained models available"
        
        models_text = "**Trained Models:**\n\n"
        
        for job in completed_jobs:
            models_text += f"**{job['model_name']}**\n"
            models_text += f"- Base Model: {job['base_model']}\n"
            models_text += f"- Training Completed: {job.get('end_time', 'Unknown')}\n"
            models_text += f"- Dataset: {os.path.basename(job['dataset_path'])}\n"
            models_text += f"- Parameters: LR={job['learning_rate']}, Batch={job['batch_size']}, Epochs={job['epochs']}\n\n"
        
        return models_text
    
    def test_model(self, model_name: str, test_input: str) -> str:
        """Test a trained model"""
        if not model_name or not test_input:
            return "Please provide both model name and test input"
        
        # Simulate model inference
        return f"**Model Response from '{model_name}':**\n\nInput: {test_input}\n\nOutput: This is a simulated response from your trained model. In a real implementation, this would be the actual model output based on your training data."

def create_gradio_interface(config: ModelTrainerConfig):
    """Create Gradio interface for LLM Model Trainer"""
    trainer = ModelTrainerAPI(config)
    
    def upload_dataset_gradio(file):
        """Handle dataset upload"""
        if file is None:
            return "No file uploaded"
        
        is_valid, message = trainer.validate_dataset(file.name)
        if is_valid:
            file_size = os.path.getsize(file.name) / 1024 / 1024
            return f"‚úÖ Dataset uploaded successfully!\n\nFile: {os.path.basename(file.name)}\nSize: {file_size:.2f} MB\nPath: {file.name}"
        else:
            return f"‚ùå Upload failed: {message}"
    
    def start_training_gradio(model_name: str, base_model: str, dataset_file, 
                             learning_rate: float, batch_size: int, epochs: int):
        """Start training for Gradio interface"""
        if dataset_file is None:
            return "Please upload a dataset first"
        
        return trainer.start_training(
            model_name, base_model, dataset_file.name,
            learning_rate, batch_size, epochs
        )
    
    def get_training_status_gradio():
        """Get training status for display"""
        return trainer.get_training_status()
    
    def get_models_gradio():
        """Get trained models for display"""
        return trainer.get_trained_models()
    
    def test_model_gradio(model_name: str, test_input: str):
        """Test model for Gradio interface"""
        return trainer.test_model(model_name, test_input)
    
    def update_brand_gradio(company_name: str, primary_color: str, secondary_color: str):
        """Update branding configuration"""
        if not company_name:
            return "Please enter a company name"
        
        brand_config = {
            'company_name': company_name,
            'primary_color': primary_color,
            'secondary_color': secondary_color,
            'updated_at': datetime.now().isoformat()
        }
        
        return f"‚úÖ Brand configuration updated!\n\n**Company:** {company_name}\n**Primary Color:** {primary_color}\n**Secondary Color:** {secondary_color}"
    
    # Create interface with custom CSS
    custom_css = """
    .gradio-container {
        max-width: 1200px !important;
    }
    .tab-nav {
        background: linear-gradient(90deg, #3b82f6, #1e40af) !important;
    }
    """
    
    with gr.Blocks(
        title="LLM Model Trainer - White Label Platform",
        css=custom_css,
        theme=gr.themes.Soft()
    ) as interface:
        
        gr.Markdown("""
        # üß† LLM Model Trainer
        ## White-Label AI Model Training Platform
        
        Train custom language models with your own datasets and deploy them with your brand.
        """)
        
        with gr.Tab("üìÅ Dataset Upload"):
            gr.Markdown("### Upload Training Dataset")
            gr.Markdown("Supported formats: JSON, JSONL, CSV, TXT (Max 100MB)")
            
            with gr.Row():
                with gr.Column():
                    dataset_file = gr.File(
                        label="Upload Dataset",
                        file_types=['.json', '.jsonl', '.csv', '.txt'],
                        file_count="single"
                    )
                    
                    data_format = gr.Dropdown(
                        choices=["Conversational (Q&A)", "Text Completion", "Text Classification", "Custom Format"],
                        label="Data Format",
                        value="Conversational (Q&A)"
                    )
                    
                    validation_split = gr.Slider(
                        minimum=10,
                        maximum=30,
                        value=20,
                        step=5,
                        label="Validation Split (%)"
                    )
                
                with gr.Column():
                    upload_status = gr.Textbox(
                        label="Upload Status",
                        lines=5,
                        interactive=False
                    )
            
            dataset_file.change(
                fn=upload_dataset_gradio,
                inputs=[dataset_file],
                outputs=upload_status
            )
        
        with gr.Tab("‚öôÔ∏è Model Configuration"):
            gr.Markdown("### Configure Model Parameters")
            
            with gr.Row():
                with gr.Column():
                    model_name = gr.Textbox(
                        label="Model Name",
                        placeholder="My Custom Model",
                        value=""
                    )
                    
                    base_model = gr.Dropdown(
                        choices=config.base_models,
                        label="Base Model",
                        value="gpt-3.5-turbo"
                    )
                    
                    learning_rate = gr.Number(
                        label="Learning Rate",
                        value=0.001,
                        minimum=0.0001,
                        maximum=0.1,
                        step=0.0001
                    )
                
                with gr.Column():
                    batch_size = gr.Number(
                        label="Batch Size",
                        value=4,
                        minimum=1,
                        maximum=32,
                        step=1
                    )
                    
                    epochs = gr.Number(
                        label="Epochs",
                        value=3,
                        minimum=1,
                        maximum=10,
                        step=1
                    )
                    
                    max_length = gr.Number(
                        label="Max Sequence Length",
                        value=2048,
                        minimum=128,
                        maximum=4096,
                        step=128
                    )
            
            model_description = gr.Textbox(
                label="Model Description",
                placeholder="Describe what this model is trained for...",
                lines=3
            )
        
        with gr.Tab("üöÄ Training"):
            gr.Markdown("### Start Model Training")
            
            with gr.Row():
                start_training_btn = gr.Button(
                    "Start Training",
                    variant="primary",
                    size="lg"
                )
                
                refresh_status_btn = gr.Button(
                    "Refresh Status",
                    variant="secondary"
                )
            
            training_output = gr.Textbox(
                label="Training Output",
                lines=8,
                interactive=False
            )
            
            training_status = gr.Markdown()
            
            start_training_btn.click(
                fn=start_training_gradio,
                inputs=[model_name, base_model, dataset_file, learning_rate, batch_size, epochs],
                outputs=training_output
            )
            
            refresh_status_btn.click(
                fn=get_training_status_gradio,
                outputs=training_status
            )
        
        with gr.Tab("ü§ñ My Models"):
            gr.Markdown("### Trained Models")
            
            with gr.Row():
                refresh_models_btn = gr.Button("Refresh Models")
                models_display = gr.Markdown()
            
            gr.Markdown("### Test Model")
            with gr.Row():
                with gr.Column():
                    test_model_name = gr.Textbox(
                        label="Model Name to Test",
                        placeholder="Enter model name"
                    )
                    
                    test_input = gr.Textbox(
                        label="Test Input",
                        placeholder="Enter text to test the model...",
                        lines=3
                    )
                    
                    test_btn = gr.Button("Test Model", variant="primary")
                
                with gr.Column():
                    test_output = gr.Textbox(
                        label="Model Response",
                        lines=8,
                        interactive=False
                    )
            
            refresh_models_btn.click(
                fn=get_models_gradio,
                outputs=models_display
            )
            
            test_btn.click(
                fn=test_model_gradio,
                inputs=[test_model_name, test_input],
                outputs=test_output
            )
        
        with gr.Tab("üé® White Label"):
            gr.Markdown("### Brand Configuration")
            gr.Markdown("Customize the platform with your brand identity")
            
            with gr.Row():
                with gr.Column():
                    company_name = gr.Textbox(
                        label="Company Name",
                        placeholder="Your Company Name"
                    )
                    
                    logo_url = gr.Textbox(
                        label="Logo URL",
                        placeholder="https://your-domain.com/logo.png"
                    )
                
                with gr.Column():
                    primary_color = gr.ColorPicker(
                        label="Primary Color",
                        value="#3b82f6"
                    )
                    
                    secondary_color = gr.ColorPicker(
                        label="Secondary Color",
                        value="#1e40af"
                    )
            
            brand_description = gr.Textbox(
                label="Brand Description",
                placeholder="Describe your brand and use case...",
                lines=3
            )
            
            with gr.Row():
                save_brand_btn = gr.Button("Save Brand Configuration", variant="primary")
                brand_output = gr.Textbox(
                    label="Brand Configuration Status",
                    lines=5,
                    interactive=False
                )
            
            save_brand_btn.click(
                fn=update_brand_gradio,
                inputs=[company_name, primary_color, secondary_color],
                outputs=brand_output
            )
        
        # Load initial data
        interface.load(
            fn=get_training_status_gradio,
            outputs=training_status
        )
        
        interface.load(
            fn=get_models_gradio,
            outputs=models_display
        )
    
    return interface

# Main execution
if __name__ == "__main__":
    config = ModelTrainerConfig()
    interface = create_gradio_interface(config)
    
    # Launch interface
    interface.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=True,
        debug=True
    )